#!/usr/bin/env python3
"""
X Profile Analyzer - ç”¨æˆ·ç”»åƒåˆ†æå·¥å…·
é€šè¿‡ Nitter (via Camofox) æŠ“å–æ¨æ–‡ï¼Œç”¨ MiniMax M2.5 API ç”Ÿæˆç»“æ„åŒ–ç”¨æˆ·ç”»åƒ

Usage:
    python3 x-profile-analyzer.py --user QingQ77
    python3 x-profile-analyzer.py --user QingQ77 --count 30 --output profile.md
"""

import json
import re
import sys
import os
import time
import argparse
import urllib.request
import urllib.error
from datetime import datetime
from typing import Optional, Dict, List, Any, Tuple
from pathlib import Path


# â”€â”€ é…ç½® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CAMOFOX_PORT = 9377
NITTER_INSTANCE = "nitter.net"
MINIMAX_API_URL = "https://api.minimax.io/anthropic/v1/messages"
AUTH_PROFILES_PATH = Path.home() / ".openclaw" / "agents" / "main" / "agent" / "auth-profiles.json"
# REFERENCE_USER å·²ç§»é™¤ï¼ˆv1.1ï¼‰


# â”€â”€ è®¤è¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_minimax_key() -> str:
    """ä» auth-profiles.json è¯»å– MiniMax API key"""
    try:
        with open(AUTH_PROFILES_PATH) as f:
            data = json.load(f)
        profiles = data.get("profiles", {})
        mm = profiles.get("minimax:default", {})
        key = mm.get("key", "")
        if not key:
            raise ValueError("minimax:default key not found")
        return key
    except FileNotFoundError:
        raise RuntimeError(f"Auth profiles not found: {AUTH_PROFILES_PATH}")
    except (KeyError, ValueError) as e:
        raise RuntimeError(f"Cannot read MiniMax key: {e}")


# â”€â”€ æ¨æ–‡æŠ“å– (Camofox + Nitter) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _extract_cursor(snapshot: str, username: str) -> Optional[str]:
    """ä»å¿«ç…§ä¸­æå–ä¸‹ä¸€é¡µ cursor"""
    import re
    cursors = re.findall(r'cursor=([^\"&\s\)]+)', snapshot)
    return cursors[0] if cursors else None

def fetch_user_timeline(username: str, count: int = 20, verbose: bool = False) -> Tuple[List[Dict], Dict]:
    """
    é€šè¿‡ Camofox + Nitter æŠ“å–ç”¨æˆ·æ—¶é—´çº¿æ¨æ–‡ï¼ˆæ”¯æŒç¿»é¡µï¼‰
    è¿”å› (tweets_list, user_info)
    """
    MAX_PAGES = 30
    all_tweets: List[Dict] = []
    user_info: Dict = {}
    cursor: Optional[str] = None

    for page in range(1, MAX_PAGES + 1):
        if cursor:
            import urllib.parse
            nitter_url = f"https://{NITTER_INSTANCE}/{username}?cursor={urllib.parse.quote(cursor, safe='')}"
        else:
            nitter_url = f"https://{NITTER_INSTANCE}/{username}"

        if verbose:
            print(f"[Fetcher] ç¬¬{page}é¡µ: {nitter_url}", file=sys.stderr)

        tab_id = _camofox_open_tab(username, nitter_url)
        if not tab_id:
            print(f"[Fetcher] ç¬¬{page}é¡µ Tab åˆ›å»ºå¤±è´¥ï¼Œåœæ­¢", file=sys.stderr)
            break

        time.sleep(8)
        snapshot = _camofox_get_snapshot(tab_id)
        _camofox_close_tab(tab_id)

        if not snapshot:
            print(f"[Fetcher] ç¬¬{page}é¡µå¿«ç…§ä¸ºç©ºï¼Œåœæ­¢", file=sys.stderr)
            break

        # ç¬¬ä¸€é¡µè§£æç”¨æˆ·ä¿¡æ¯
        if page == 1:
            user_info = _parse_user_info(snapshot, username)

        page_tweets = _parse_tweets(snapshot, username, count)
        if not page_tweets:
            if verbose:
                print(f"[Fetcher] ç¬¬{page}é¡µæ— æ¨æ–‡ï¼Œåœæ­¢ç¿»é¡µ", file=sys.stderr)
            break

        all_tweets.extend(page_tweets)
        if verbose:
            print(f"[Fetcher] ç¬¬{page}é¡µæŠ“åˆ° {len(page_tweets)} æ¡ï¼Œç´¯è®¡ {len(all_tweets)} æ¡", file=sys.stderr)

        if len(all_tweets) >= count:
            break

        cursor = _extract_cursor(snapshot, username)
        if not cursor:
            if verbose:
                print(f"[Fetcher] æ— ä¸‹ä¸€é¡µ cursorï¼Œåœæ­¢", file=sys.stderr)
            break

    all_tweets = all_tweets[:count]
    if verbose:
        print(f"[Fetcher] æœ€ç»ˆå…± {len(all_tweets)} æ¡æ¨æ–‡", file=sys.stderr)

    return all_tweets, user_info


def _camofox_open_tab(username: str, url: str) -> Optional[str]:
    """åœ¨ Camofox ä¸­æ‰“å¼€æ–° Tabï¼Œè¿”å› tab_id"""
    try:
        create_data = json.dumps({
            "userId": "x-profile-analyzer",
            "sessionKey": f"profile-{username}-{int(time.time())}",
            "url": url,
        }).encode()

        req = urllib.request.Request(
            f"http://localhost:{CAMOFOX_PORT}/tabs",
            data=create_data,
            headers={"Content-Type": "application/json"},
            method="POST",
        )
        with urllib.request.urlopen(req, timeout=10) as resp:
            tab_data = json.loads(resp.read().decode())

        return tab_data.get("tabId")
    except Exception as e:
        print(f"[Camofox] Error opening tab: {e}", file=sys.stderr)
        return None


def _camofox_get_snapshot(tab_id: str, user_id: str = "x-profile-analyzer") -> str:
    """è·å– Tab å¿«ç…§ï¼ˆuserId å¿…é¡»ä¸åˆ›å»ºæ—¶ä¸€è‡´ï¼‰"""
    try:
        snap_url = f"http://localhost:{CAMOFOX_PORT}/tabs/{tab_id}/snapshot?userId={user_id}"
        req = urllib.request.Request(snap_url)
        with urllib.request.urlopen(req, timeout=15) as resp:
            raw = resp.read().decode("utf-8", errors="replace")
            snap_data = json.loads(raw)
        return snap_data.get("snapshot", "")
    except Exception as e:
        print(f"[Camofox] Error getting snapshot: {e}", file=sys.stderr)
        return ""


def _camofox_close_tab(tab_id: str):
    """å…³é—­ Tab"""
    try:
        close_req = urllib.request.Request(
            f"http://localhost:{CAMOFOX_PORT}/tabs/{tab_id}",
            method="DELETE",
        )
        urllib.request.urlopen(close_req, timeout=5)
    except Exception:
        pass


def _parse_user_info(snapshot: str, username: str) -> Dict:
    """ä»å¿«ç…§ä¸­è§£æç”¨æˆ·åŸºæœ¬ä¿¡æ¯"""
    info = {
        "username": username,
        "display_name": "",
        "bio": "",
        "joined": "",
        "tweets_count": 0,
        "followers": 0,
        "following": 0,
    }

    lines = snapshot.split("\n")
    for i, line in enumerate(lines):
        line = line.strip()

        # æ˜¾ç¤ºåç§°
        if not info["display_name"]:
            m = re.search(r'link\s+"([^@"][^"]+)"\s+\[e\d+\]:', line)
            if m and username.lower() not in m.group(1).lower():
                name = m.group(1)
                if name not in ("nitter", "Logo"):
                    info["display_name"] = name

        # Bio
        if line.startswith("- paragraph:") and not info["bio"]:
            bio = line.replace("- paragraph:", "").strip()
            if bio and "Joined" not in bio:
                info["bio"] = bio

        # Joined
        if "Joined" in line and not info["joined"]:
            m = re.search(r"Joined\s+(.+)", line)
            if m:
                info["joined"] = m.group(1).strip()

        # Stats
        if "Tweets " in line:
            m = re.search(r"Tweets\s+([\d,]+)", line)
            if m:
                info["tweets_count"] = int(m.group(1).replace(",", ""))
        if "Followers " in line:
            m = re.search(r"Followers\s+([\d,]+)", line)
            if m:
                info["followers"] = int(m.group(1).replace(",", ""))
        if "Following " in line:
            m = re.search(r"Following\s+([\d,]+)", line)
            if m:
                info["following"] = int(m.group(1).replace(",", ""))

    return info


def _parse_tweets(snapshot: str, username: str, max_count: int) -> List[Dict]:
    """ä»å¿«ç…§è§£ææ¨æ–‡åˆ—è¡¨"""
    tweets = []
    lines = snapshot.split("\n")

    i = 0
    while i < len(lines) and len(tweets) < max_count:
        line = lines[i].strip()

        # æ£€æµ‹æ¨æ–‡å¼€å¤´: æ—¶é—´é“¾æ¥ (å¦‚ "27m", "9h", "3d")
        time_m = re.search(r'link\s+"(\d+[smhd]|(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\s+\d+(?:,\s+\d{4})?)"\s+\[e\d+\]:', line)
        if not time_m:
            i += 1
            continue

        # ç¡®è®¤è¿™æ˜¯è¯¥ç”¨æˆ·çš„æ¨æ–‡ (å‰å‡ è¡Œåº”æœ‰ @username)
        is_own_tweet = False
        for j in range(max(0, i - 5), i):
            if f'@{username.lower()}' in lines[j].lower() or f'/{username.lower()}' in lines[j].lower():
                is_own_tweet = True
                break

        if not is_own_tweet:
            i += 1
            continue

        time_str = time_m.group(1)
        tweet_url_m = re.search(r'/url:\s*(/\w+/status/\d+)', lines[i])
        tweet_url = tweet_url_m.group(1) if tweet_url_m else ""

        # æ”¶é›†æ¨æ–‡æ–‡æœ¬ï¼ˆæ¥ä¸‹æ¥çš„æ–‡æœ¬è¡Œï¼‰
        tweet_text_parts = []
        stats_str = ""
        media_urls = []
        quoted_text = ""

        j = i + 1
        while j < min(i + 30, len(lines)):
            next_line = lines[j].strip()

            # ä¸‹ä¸€æ¡æ¨æ–‡å¼€å§‹ï¼ˆæ–°çš„æ—¶é—´é“¾æ¥ï¼‰
            if re.search(r'link\s+"(\d+[smhd]|(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\s+\d+)"\s+\[e\d+\]:', next_line):
                break

            # æ¨æ–‡æ–‡æœ¬
            if next_line.startswith("- text:") and not next_line.startswith("- text:  "):
                text = next_line.replace("- text:", "").strip()
                # è·³è¿‡ç»Ÿè®¡è¡Œï¼ˆçº¯æ•°å­—+ç©ºæ ¼ï¼‰
                if re.match(r'^[\d\s]+$', text):
                    stats_str = text
                elif text and text not in ("Replying to", "Pinned Tweet"):
                    tweet_text_parts.append(text)

            # åª’ä½“é“¾æ¥
            if "- /url: /pic/" in next_line:
                media_urls.append(next_line.strip())

            # å¼•ç”¨æ¨æ–‡æ–‡æœ¬
            if "- paragraph:" in next_line and j > i + 3:
                quoted_text = next_line.replace("- paragraph:", "").strip()

            j += 1

        tweet_text = " ".join(tweet_text_parts).strip()

        # è§£æäº’åŠ¨æ•°æ®ï¼ˆä» stats_str æå–æ•°å­—ï¼‰
        stats_nums = [int(x) for x in re.findall(r'\d+', stats_str)] if stats_str else []
        replies_count = stats_nums[0] if len(stats_nums) > 0 else 0
        retweets = stats_nums[1] if len(stats_nums) > 1 else 0
        views = stats_nums[2] if len(stats_nums) > 2 else 0

        if tweet_text:  # åªä¿ç•™æœ‰æ–‡æœ¬çš„æ¨æ–‡
            tweet = {
                "text": tweet_text,
                "time": time_str,
                "url": f"https://x.com{tweet_url}" if tweet_url else "",
                "replies": replies_count,
                "retweets": retweets,
                "views": views,
                "has_media": len(media_urls) > 0,
                "quoted_text": quoted_text,
            }
            tweets.append(tweet)

        i = j

    return tweets


# â”€â”€ MiniMax M2.5 åˆ†æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def analyze_profile_with_minimax(
    user_info: Dict,
    tweets: List[Dict],
    api_key: str,
    verbose: bool = False,
) -> str:
    """è°ƒç”¨ MiniMax M2.5 API ç”Ÿæˆç”¨æˆ·ç”»åƒåˆ†æ"""

    # æ„å»ºæ¨æ–‡æ‘˜è¦
    tweets_summary = _build_tweets_summary(tweets)
    user_summary = _build_user_summary(user_info)

    prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç¤¾äº¤åª’ä½“ç”¨æˆ·åˆ†æå¸ˆã€‚è¯·åŸºäºä»¥ä¸‹ @{user_info['username']} çš„æ¨æ–‡æ•°æ®ï¼Œç”Ÿæˆä¸€ä»½è¯¦ç»†çš„ç”¨æˆ·ç”»åƒåˆ†ææŠ¥å‘Šã€‚

## ç”¨æˆ·åŸºæœ¬ä¿¡æ¯
{user_summary}

## æœ€è¿‘æ¨æ–‡ï¼ˆå…± {len(tweets)} æ¡ï¼‰
{tweets_summary}

## åˆ†æè¦æ±‚
è¯·è¾“å‡ºç»“æ„åŒ–çš„ Markdown æ ¼å¼æŠ¥å‘Šï¼ŒåŒ…å«ä»¥ä¸‹ç« èŠ‚ï¼š

1. **è¯é¢˜åå¥½** - è¯¥ç”¨æˆ·æœ€å¸¸è®¨è®ºçš„ä¸»é¢˜ã€å…³æ³¨é¢†åŸŸã€å…´è¶£æ–¹å‘ï¼Œç»™å‡ºå…·ä½“ä¾‹å­
2. **å†™ä½œé£æ ¼** - è¡¨è¾¾æ–¹å¼ã€è¯­è¨€ä¹ æƒ¯ã€å¥å¼ç‰¹ç‚¹ã€è¡¨æƒ…ç¬¦å·ä½¿ç”¨ï¼Œå¼•ç”¨å®é™…æ¨æ–‡åŸæ–‡ä¸¾ä¾‹
3. **äº’åŠ¨ä¹ æƒ¯** - å‘æ¨é¢‘ç‡ã€å›å¤ä¹ æƒ¯ã€è½¬å‘è¡Œä¸ºï¼Œåˆ†æå…¶ç¤¾äº¤å®šä½ï¼ˆå¹¿æ’­å‹/äº’åŠ¨å‹/æ½œæ°´å‹ï¼‰
4. **æŠ€æœ¯æ–¹å‘** - æ¶‰åŠçš„æŠ€æœ¯æ ˆã€å·¥å…·ã€é¡¹ç›®ã€æŠ€æœ¯è§‚ç‚¹ï¼ˆå¦‚æ— æ˜æ˜¾æŠ€æœ¯å†…å®¹åˆ™æ ‡æ³¨ï¼‰
5. **æ·±å±‚åŠ¨æœºåˆ†æ** - åŸºäºæ¨æ–‡å†…å®¹æ¨æ–­ï¼šè¿™ä¸ªäººå‘æ¨çš„æ ¸å¿ƒé©±åŠ¨åŠ›æ˜¯ä»€ä¹ˆï¼Ÿä»–/å¥¹åœ¨è¿½æ±‚ä»€ä¹ˆï¼Ÿæœ‰ä»€ä¹ˆæ½œåœ¨çš„ç„¦è™‘æˆ–æ‰§å¿µï¼Ÿè¿™æ˜¯æŠ¥å‘Šçš„æ ¸å¿ƒç« èŠ‚ï¼Œè¦æœ‰æ´å¯ŸåŠ›ï¼Œä¸è¦æ³›æ³›è€Œè°ˆ
6. **è¡Œä¸ºé¢„æµ‹** - åŸºäºå†å²æ¨æ–‡ï¼Œé¢„æµ‹è¿™ä¸ªäººæ¥ä¸‹æ¥æœ€å¯èƒ½åšä»€ä¹ˆï¼Œä¼šå…³æ³¨å“ªäº›è¯é¢˜ï¼Œå¯èƒ½çš„è½¬å˜æ–¹å‘
7. **AI æµ‹ç®—æ˜Ÿåº§** - æ ¹æ®æ¨æ–‡é£æ ¼ã€è¡¨è¾¾ä¹ æƒ¯ã€å…³æ³¨è¯é¢˜ï¼Œç”¨å æ˜Ÿå­¦è§†è§’ç»™å‡º"æœ€åƒå“ªä¸ªæ˜Ÿåº§"ï¼Œé™„ä¸Š 2-3 å¥æœ‰è¶£ç†ç”±ï¼ˆå¨±ä¹å‘ï¼‰
8. **ä¸€å¥è¯äººç‰©é€Ÿå†™** - ç”¨ä¸€å¥è¯ç²¾å‡†æ¦‚æ‹¬è¿™ä¸ªäººï¼Œè¦æœ‰è®°å¿†ç‚¹ï¼Œåƒä¸€ä¸ªå¥½çš„äººç‰©ä¼ è®°å¼€å¤´

è¯·ä¿æŒåˆ†ææ·±åˆ»ã€å…·ä½“ã€æœ‰æ´å¯ŸåŠ›ï¼ŒåŸºäºå®é™…æ¨æ–‡å†…å®¹ï¼Œé¿å…å¥—è¯ã€‚"""

    if verbose:
        print(f"[MiniMax] Sending {len(tweets)} tweets for analysis...", file=sys.stderr)

    try:
        request_body = json.dumps({
            "model": "MiniMax-M1",
            "max_tokens": 4096,
            "messages": [
                {
                    "role": "user",
                    "content": prompt,
                }
            ],
        }).encode("utf-8")

        req = urllib.request.Request(
            MINIMAX_API_URL,
            data=request_body,
            headers={
                "Content-Type": "application/json",
                "x-api-key": api_key,
                "anthropic-version": "2023-06-01",
            },
            method="POST",
        )

        with urllib.request.urlopen(req, timeout=120) as resp:
            result = json.loads(resp.read().decode("utf-8"))

        # æå–æ–‡æœ¬
        content = result.get("content", [])
        for block in content:
            if block.get("type") == "text":
                return block["text"]

        return f"[Error] Unexpected API response format: {json.dumps(result)[:500]}"

    except urllib.error.HTTPError as e:
        body = e.read().decode("utf-8", errors="replace")[:500]
        raise RuntimeError(f"MiniMax API HTTP {e.code}: {body}")
    except urllib.error.URLError as e:
        raise RuntimeError(f"MiniMax API connection error: {e.reason}")
    except TimeoutError:
        raise RuntimeError("MiniMax API request timed out (>120s). Try reducing --count.")


def _build_user_summary(user_info: Dict) -> str:
    lines = [
        f"- ç”¨æˆ·å: @{user_info.get('username', 'unknown')}",
        f"- æ˜¾ç¤ºåç§°: {user_info.get('display_name', 'N/A')}",
        f"- ç®€ä»‹: {user_info.get('bio', 'N/A')}",
        f"- åŠ å…¥æ—¶é—´: {user_info.get('joined', 'N/A')}",
        f"- æ¨æ–‡æ•°: {user_info.get('tweets_count', 0):,}",
        f"- ç²‰ä¸æ•°: {user_info.get('followers', 0):,}",
        f"- å…³æ³¨æ•°: {user_info.get('following', 0):,}",
    ]
    return "\n".join(lines)


def _build_tweets_summary(tweets: List[Dict]) -> str:
    parts = []
    for i, t in enumerate(tweets, 1):
        text = t["text"]
        stats = f"å›å¤:{t['replies']} è½¬æ¨:{t['retweets']} æµè§ˆ:{t['views']}"
        has_media = "ğŸ“·" if t.get("has_media") else ""
        quoted = f"\n  > å¼•ç”¨: {t['quoted_text'][:100]}" if t.get("quoted_text") else ""
        parts.append(f"{i}. [{t['time']}] {has_media}{text[:300]}{quoted}\n   ({stats})")
    return "\n\n".join(parts)


# â”€â”€ è¾“å‡ºæ ¼å¼åŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def format_report(user_info: Dict, tweets: List[Dict], analysis: str) -> str:
    """ç”Ÿæˆæœ€ç»ˆ Markdown æŠ¥å‘Š"""
    now = datetime.now().strftime("%Y-%m-%d %H:%M")
    username = user_info.get("username", "unknown")
    display_name = user_info.get("display_name", username)
    tweet_count = len(tweets)

    # æ•°æ®è´¨é‡æ ‡æ³¨
    if tweet_count < 50:
        data_quality = f"âš ï¸ ä½ï¼ˆä»… {tweet_count} æ¡ï¼ŒNitter å¯¹è¯¥è´¦å·æ”¶å½•ä¸è¶³ï¼Œç»“æœä»…ä¾›å‚è€ƒï¼‰"
    elif tweet_count < 100:
        data_quality = f"âš¡ ä¸­ï¼ˆ{tweet_count} æ¡ï¼Œå»ºè®® 100+ æ¡è·å¾—æ›´å‡†ç¡®åˆ†æï¼‰"
    else:
        data_quality = f"âœ… é«˜ï¼ˆ{tweet_count} æ¡ï¼‰"

    header = f"""# ç”¨æˆ·ç”»åƒåˆ†ææŠ¥å‘Šï¼š@{username}

> ç”Ÿæˆæ—¶é—´ï¼š{now}
> åˆ†æå·¥å…·ï¼šx-profile-analyzer v1.2
> æ•°æ®æ¥æºï¼šNitter / X.com
> æ•°æ®è´¨é‡ï¼š{data_quality}

## åŸºæœ¬ä¿¡æ¯

| å­—æ®µ | å€¼ |
|------|-----|
| ç”¨æˆ·å | @{username} |
| æ˜¾ç¤ºåç§° | {display_name} |
| ç®€ä»‹ | {user_info.get('bio', 'N/A')} |
| åŠ å…¥æ—¶é—´ | {user_info.get('joined', 'N/A')} |
| æ¨æ–‡æ•° | {user_info.get('tweets_count', 0):,} |
| ç²‰ä¸æ•° | {user_info.get('followers', 0):,} |
| å…³æ³¨æ•° | {user_info.get('following', 0):,} |

*æœ¬æ¬¡åˆ†æåŸºäºæœ€è¿‘ {len(tweets)} æ¡æ¨æ–‡*

---

"""

    return header + analysis + f"\n\n---\n*åˆ†æç”± MiniMax M2.5 ç”Ÿæˆ | x-profile-analyzer v1.1*\n"


# â”€â”€ ä¸»ç¨‹åº â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    parser = argparse.ArgumentParser(
        description="X ç”¨æˆ·ç”»åƒåˆ†æå·¥å…· - æŠ“å–æ¨æ–‡å¹¶ç”Ÿæˆç»“æ„åŒ–åˆ†ææŠ¥å‘Š"
    )
    parser.add_argument("--user", "-u", required=True, help="X/Twitter ç”¨æˆ·åï¼ˆä¸å« @ï¼‰")
    parser.add_argument("--count", "-c", type=int, default=300, help="åˆ†ææ¨æ–‡æ•°é‡ï¼ˆé»˜è®¤ 300ï¼Œå°½å¯èƒ½æŠ“æœ€å¤šï¼ŒNitter å®é™…ä¸Šé™çº¦ 300ï¼‰")
    parser.add_argument("--output", "-o", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤è¾“å‡ºåˆ° stdoutï¼‰")
    parser.add_argument("--verbose", "-v", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†è¿›åº¦ä¿¡æ¯")
    parser.add_argument("--no-camofox", action="store_true", help="è·³è¿‡ Camofox æ£€æŸ¥ï¼ˆè°ƒè¯•ç”¨ï¼‰")
    args = parser.parse_args()

    username = args.user.lstrip("@")

    # æ£€æŸ¥ Camofox çŠ¶æ€
    if not args.no_camofox:
        try:
            req = urllib.request.Request(f"http://localhost:{CAMOFOX_PORT}/")
            with urllib.request.urlopen(req, timeout=3) as resp:
                status = json.loads(resp.read().decode())
            if not status.get("running"):
                print(f"[Error] Camofox is not running. Start it first.", file=sys.stderr)
                sys.exit(1)
            if args.verbose:
                print(f"[Camofox] Status: OK (browser connected: {status.get('browserConnected')})", file=sys.stderr)
        except Exception as e:
            print(f"[Error] Cannot connect to Camofox at port {CAMOFOX_PORT}: {e}", file=sys.stderr)
            print("Make sure Camofox is running.", file=sys.stderr)
            sys.exit(1)

    # åŠ è½½ API Key
    try:
        api_key = load_minimax_key()
        if args.verbose:
            print(f"[Auth] MiniMax API key loaded: {api_key[:15]}...", file=sys.stderr)
    except RuntimeError as e:
        print(f"[Error] {e}", file=sys.stderr)
        sys.exit(1)

    # æŠ“å–æ¨æ–‡
    print(f"ğŸ“Š æ­£åœ¨æŠ“å– @{username} çš„æ¨æ–‡...", file=sys.stderr)
    try:
        tweets, user_info = fetch_user_timeline(username, args.count, verbose=args.verbose)
    except RuntimeError as e:
        print(f"[Error] Failed to fetch tweets: {e}", file=sys.stderr)
        sys.exit(1)

    if not tweets:
        print(f"[Warning] No tweets found for @{username}. Account may be protected or not exist.", file=sys.stderr)
        sys.exit(1)

    print(f"âœ… æˆåŠŸè·å– {len(tweets)} æ¡æ¨æ–‡", file=sys.stderr)

    # æ•°æ®è´¨é‡æç¤º
    if len(tweets) < 50:
        print(f"âš ï¸  æ•°æ®ä¸è¶³ï¼ˆä»… {len(tweets)} æ¡ï¼‰ï¼šè¯¥è´¦å·åœ¨ Nitter æ”¶å½•è¾ƒå°‘ï¼Œå¯èƒ½æ˜¯å°è´¦å·æˆ–ä½æ´»è·ƒåº¦è´¦å·ï¼Œåˆ†æç»“æœä»…ä¾›å‚è€ƒ", file=sys.stderr)
    elif len(tweets) < 100:
        print(f"âš ï¸  æ•°æ®åå°‘ï¼ˆ{len(tweets)} æ¡ï¼‰ï¼šå»ºè®® 100 æ¡ä»¥ä¸Šä»¥è·å¾—æ›´å‡†ç¡®çš„åˆ†æ", file=sys.stderr)


    # AI åˆ†æ
    print(f"ğŸ¤– æ­£åœ¨ç”¨ MiniMax M2.5 åˆ†æç”¨æˆ·ç”»åƒ...", file=sys.stderr)
    try:
        analysis = analyze_profile_with_minimax(user_info, tweets, api_key, verbose=args.verbose)
    except RuntimeError as e:
        print(f"[Error] Analysis failed: {e}", file=sys.stderr)
        sys.exit(1)

    # æ ¼å¼åŒ–æŠ¥å‘Š
    report = format_report(user_info, tweets, analysis)

    # è¾“å‡º
    if args.output:
        output_path = Path(args.output)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        output_path.write_text(report, encoding="utf-8")
        print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}", file=sys.stderr)
    else:
        print(report)


if __name__ == "__main__":
    main()
